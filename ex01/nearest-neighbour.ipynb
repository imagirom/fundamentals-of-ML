{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Nearest Neighbor Classification on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits ()\n",
    "print(digits.keys())\n",
    "data = digits[\"data\"]\n",
    "images = digits[\"images\"]\n",
    "target = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(data.dtype)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4kROJDYvwFBuZfzuATFqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x30b70d52e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images[3]\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_all = data\n",
    "y_all = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(digits.data, digits.target, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Distance function computation using loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_loop(training, test):\n",
    "    N = training.shape[0]\n",
    "    M = test.shape[0]\n",
    "    dists = np.empty((N,M), dtype=np.float32)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            dists[i,j] = np.linalg.norm(training[i] - test[j])\n",
    "            \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.01 s ± 91.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dist_loop(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Distance function computation using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_vec(training, test):\n",
    "    return np.linalg.norm(training[:,np.newaxis,:] - test[np.newaxis,:,:], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 ms ± 7.23 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dist_vec(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Implement the nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def rule_k_nearest_neighbors(k, training, train_labels, test):\n",
    "    M = test.shape[0]\n",
    "    dists = dist_vec(training, test) #N*M\n",
    "    k_smallest = np.argpartition(dists, k, axis=0)[:k,:] #k*M\n",
    "    labels = train_labels[k_smallest.flatten()].reshape(k,M)\n",
    "    return stats.mode(labels, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for distinguishing 1s and 3s: 0.0000\n",
      "error for distinguishing 1s and 7s: 0.0000\n",
      "error for distinguishing 3s and 9s: 0.0139\n"
     ]
    }
   ],
   "source": [
    "def two_digit_error(i, j, k=1):\n",
    "    pos_train = (y_train == i) | (y_train == j)\n",
    "    X_train_ij = X_train[pos_train]\n",
    "    y_train_ij = y_train[pos_train]\n",
    "    pos_test = (y_test == i) | (y_test == j)\n",
    "    X_test_ij = X_test[pos_test]\n",
    "    y_test_ij = y_test[pos_test]\n",
    "\n",
    "    return np.count_nonzero(rule_k_nearest_neighbors(k, X_train_ij, y_train_ij, X_test_ij) - y_test_ij) / y_test_ij.size\n",
    "\n",
    "print(\"error for distinguishing 1s and 3s: {:5.4f}\".format(two_digit_error(1,3)))\n",
    "print(\"error for distinguishing 1s and 7s: {:5.4f}\".format(two_digit_error(1,7)))\n",
    "print(\"error for distinguishing 3s and 9s: {:5.4f}\".format(two_digit_error(3,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Generalize to k-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinguishing 3s and 9s:\n",
      "k =  1, error = 0.0139\n",
      "k =  3, error = 0.0069\n",
      "k =  5, error = 0.0069\n",
      "k =  9, error = 0.0069\n",
      "k = 17, error = 0.0069\n",
      "k = 33, error = 0.0208\n"
     ]
    }
   ],
   "source": [
    "ks = [1,3,5,9,17,33]\n",
    "print(\"distinguishing 3s and 9s:\")\n",
    "for k in ks:\n",
    "    print(\"k = {:2d}, error = {:5.4f}\".format(k, two_digit_error(3, 9, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification performance is best for intermediate values of k. Between k=3 and k=17 the minimal error rate of 0.7% is achieved, the extreme values of k=1 and k=33 yield significantly worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(X, y, n):\n",
    "    return np.array_split(X, n), np.array_split(y, n)\n",
    "\n",
    "\n",
    "def generate_CV_sets(X, y, n):\n",
    "    X_folds, y_folds = generate_folds(X, y, n)\n",
    "    splits = np.array_split(np.arange(len(X)), n)\n",
    "    dsets = []\n",
    "    for i in range(n):\n",
    "        X_train = np.delete(X, splits[i], axis=0)\n",
    "        y_train = np.delete(y, splits[i], axis=0)\n",
    "        X_test = X_folds[i]\n",
    "        y_test = y_folds[i]\n",
    "        dsets.append([X_train, y_train, X_test, y_test])\n",
    "    return dsets\n",
    "\n",
    "# rule is a function of the form (X_train, y_train, X_test) -> y_test\n",
    "def cross_validation_error(rule, X, y, n):\n",
    "    dsets = generate_CV_sets(X, y, n)\n",
    "    errors = np.empty(n, dtype=np.float32)\n",
    "    for i, dset in enumerate(dsets):\n",
    "        X_train, y_train, X_test, y_test = dset\n",
    "        y_test_predicted = rule(X_train, y_train, X_test)\n",
    "        errors[i] = np.average(y_test_predicted != y_test)\n",
    "    return np.average(errors), np.std(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------own implementation---------------\n",
      "n =  2, mean error = 0.0406, error std = 0.0016\n",
      "n =  5, mean error = 0.0350, error std = 0.0129\n",
      "n = 10, mean error = 0.0239, error std = 0.0176\n",
      "---------sklearn KNeighborsClassifier----------\n",
      "n =  2, mean error = 0.0401, error std = 0.0011\n",
      "n =  5, mean error = 0.0350, error std = 0.0129\n",
      "n = 10, mean error = 0.0239, error std = 0.0176\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "X, y = data, target\n",
    "ns = [2,5,10]\n",
    "\n",
    "own_rule = lambda X_train, y_train, X_test: rule_k_nearest_neighbors(1, X_train, y_train, X_test)\n",
    "\n",
    "def sklearn_rule(X_train, y_train, X_test):\n",
    "    sklearn_NN = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "    sklearn_NN.fit(X_train, y_train)\n",
    "    return sklearn_NN.predict(X_test)\n",
    "    \n",
    "print(\"-\"*14+\"own implementation\"+\"-\"*15)\n",
    "for n in ns:\n",
    "    error, error_std = cross_validation_error(own_rule, X, y, n)\n",
    "    print(\"n = {:2d}, mean error = {:5.4f}, error std = {:5.4f}\".format(n, error, error_std))\n",
    "\n",
    "\n",
    "print(\"-\"*9+\"sklearn KNeighborsClassifier\"+\"-\"*10)\n",
    "for n in ns:\n",
    "    error, error_std = cross_validation_error(sklearn_rule, X, y, n)\n",
    "    print(\"n = {:2d}, mean error = {:5.4f}, error std = {:5.4f}\".format(n, error, error_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
